Here is your consolidated documentation, cleaned up for clarity and conciseness.

# AWS & Development Environment Setup Guide

## 1. Python Virtual Environment Management

### Prerequisites & Creation

One-time setup to install `venv` and create a new environment.

```bash
# Install venv module
sudo apt update
sudo apt install python3-venv

# Create environment (replace 'my_env' with preferred name)
python3 -m venv my_env

```

### Manage Environment

Commands to activate, verify, and deactivate the environment.

* **Activate:**
```bash
source my_env/bin/activate

```


*(Visual Indicator: Prompt changes to `(my_env) user@hostname:~$`)*
* **Verify Active Python:**
```bash
which python
# Output should point to: .../my_env/bin/python

```


* **Deactivate:**
```bash
deactivate

```



---

## 2. Troubleshooting `boto3` Import Errors

If "Import 'boto3' could not be resolved" appears, follow these steps:

### A. Terminal Fix (Install Package)

Ensure the environment is active and install the library.

```bash
source my_env/bin/activate
pip install boto3

```

*Verify installation:* `python -c "import boto3; print(boto3.__version__)"`

### B. VS Code Fix (Select Interpreter)

If VS Code still shows an error despite installation:

1. Press `Ctrl` + `Shift` + `P`.
2. Select **Python: Select Interpreter**.
3. Choose the entry labeled **`('my_env': venv)`** or `./my_env/bin/python`.
4. Restart the VS Code terminal.

---

## 3. AWS Serverless CORS Configuration

**Issue:** Browser blocks frontend requests to API Gateway due to missing CORS headers.
**Solution:** Update the Lambda function to return `Access-Control-Allow-` headers.

### Update `producer.py`

Modify the return statement in your Lambda handler:

```python
import json
import boto3
import os

sqs = boto3.client('sqs')
QUEUE_URL = os.environ['SQS_QUEUE_URL']

def lambda_handler(event, context):
    try:
        body = json.loads(event['body'])
        
        sqs.send_message(
            QueueUrl=QUEUE_URL,
            MessageBody=json.dumps(body)
        )
        
        return {
            'statusCode': 200,
            # --- CORS HEADERS START ---
            'headers': {
                'Access-Control-Allow-Origin': '*', 
                'Access-Control-Allow-Headers': 'Content-Type',
                'Access-Control-Allow-Methods': 'OPTIONS,POST,GET'
            },
            # --- CORS HEADERS END ---
            'body': json.dumps('Order placed successfully!')
        }
    except Exception as e:
        return {
            'statusCode': 500,
            'headers': {
                'Access-Control-Allow-Origin': '*',
                'Access-Control-Allow-Headers': 'Content-Type',
                'Access-Control-Allow-Methods': 'OPTIONS,POST,GET'
            },
            'body': str(e)
        }

```

### Apply Changes

Redeploy the infrastructure to update the Lambda code.

```bash
terraform apply -auto-approve

```

---

## 4. Git Maintenance Commands

### Untrack Files (Without Deleting)

Remove files (like `.terraform/` or `venv/`) from the Git index if explicitly committed.

```bash
git rm -r --cached .

```

### Auto-Setup Remote Branch

Configure Git to automatically set the upstream branch on push.

```bash
git config --global push.autoSetupRemote true

```

---

## 5. VS Code Configuration (Format on Save)

### `settings.json` Configuration

1. Press `Ctrl` + `Shift` + `P` -> **Open User Settings (JSON)**.
2. Paste the following to enable formatters for Terraform, Python, JS, Java, Scala, and SQL.

```json
{
    "explorer.confirmDelete": false,
    "explorer.confirmDragAndDrop": false,
    "security.workspace.trust.untrustedFiles": "open",
    "python.defaultInterpreterPath": "/bin/python3",
    "aws.cloudformation.telemetry.enabled": false,
    "gitlens.ai.model": "vscode",
    "gitlens.ai.vscode.model": "copilot:gpt-4.1",
    "[terraform]": {
        "editor.defaultFormatter": "hashicorp.terraform",
        "editor.formatOnSave": true,
        "editor.formatOnSaveMode": "file"
    },
    "[terraform-vars]": {
        "editor.defaultFormatter": "hashicorp.terraform",
        "editor.formatOnSave": true,
        "editor.formatOnSaveMode": "file"
    },
    "[python]": {
        "editor.defaultFormatter": "ms-python.black-formatter",
        "editor.formatOnSave": true
    },
    "[javascript]": {
        "editor.defaultFormatter": "esbenp.prettier-vscode",
        "editor.formatOnSave": true
    },
    "[typescript]": {
        "editor.defaultFormatter": "esbenp.prettier-vscode",
        "editor.formatOnSave": true
    },
    "[java]": {
        "editor.defaultFormatter": "redhat.java",
        "editor.formatOnSave": true
    },
    "[scala]": {
        "editor.defaultFormatter": "scalameta.metals",
        "editor.formatOnSave": true
    },
    "[sql]": {
        "editor.defaultFormatter": "mtxr.sqltools",
        "editor.formatOnSave": true
    }
}

```

### Install Required Extensions

Run in terminal to install formatters referenced in `settings.json`.

```bash
# Python
code --install-extension ms-python.black-formatter
# JS/TS
code --install-extension esbenp.prettier-vscode
# Java
code --install-extension redhat.java
# Scala
code --install-extension scalameta.metals
# SQL
code --install-extension mtxr.sqltools

```

---

## 6. GitHub Actions: Terraform Validation

Automate syntax checking on Pull Requests.

### Setup Workflow

1. Create directory: `mkdir -p .github/workflows`
2. Create `.github/workflows/terraform-check.yml`:

```yaml
name: Terraform Check

on:
  pull_request:
    branches:
      - main

jobs:
  validate:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v2
        with:
          terraform_version: 1.5.0 

      # Init without backend to avoid AWS credential requirements
      - name: Terraform Init
        run: terraform init -backend=false

      - name: Terraform Format
        run: terraform fmt -check

      - name: Terraform Validate
        run: terraform validate

```

### Push to Repository

```bash
git add .github/workflows/terraform-check.yml
git commit -m "Add Terraform validation CI"
git push

```
--------- use curl command on terminal to send request to API -------------

curl -X POST -H "Content-Type: application/json" \
-d '{"product": "Poison", "quantity": 1}' \
"https://rplpsmjlf5.execute-api.us-east-1.amazonaws.com/prod/order"

Here is the breakdown of that `curl` command.

**`curl`** (Client URL) is a command-line tool for transferring data to or from a server.

### The Breakdown

* **`-X POST`**
**The Action.** It tells the server you want to **send** data (create a new order), rather than just read it (`GET`).
* **`-H "Content-Type: application/json"`**
**The Header.** It tells the server: *"The data I am about to send you is formatted as JSON, not plain text or HTML."*
* **`-d '{"product": "Poison", "quantity": 1}'`**
**The Data.** This is the actual payload (body) you are sending. In this case, it is a JSON object representing an order.
* **`"https://..."`**
**The Destination.** The specific API Gateway endpoint that will receive and process your request.

### In Plain English

> "Hey API, I am **POST**ing some **JSON data** to you. Here is an order for **1 unit of Poison**. Please process it."

**Would you like to know how to save the response of this command to a file (e.g., `response.json`) so you can inspect it easier?**


------------ sqs - how to handle dead letter queue (dlq) ----------------------

1. Step A: Fix the "Bug" (The Consumer)
First, let's remove the "Chaos Mode" code you added, so the Consumer Lambda can successfully process the "Poison" order this time.

Open consumer.py.

Remove or Comment out the poisoning logic:

def lambda_handler(event, context):
    for record in event['Records']:
        payload = json.loads(record['body'])
        
        # --- CHAOS MODE REMOVED ---
        # if payload.get('product') == "Poison":
        #    raise Exception("This order is poisonous!")
        # --------------------------

        # ... rest of code

5. Advanced Note (For your Expert Goal)
In a massive production system with thousands of errors, you wouldn't use the Console manually. You would likely use:

EventBridge Pipes: To automatically filter and route specific DLQ errors to different places.

Lambda "Redriver": A specific Lambda function that triggers off the DLQ, sanitizes bad data (e.g., fixes missing fields), and resubmits it.




api_url = "https://rplpsmjlf5.execute-api.us-east-1.amazonaws.com/prod/order"
website_url = "serverless-frontend-20260113093148018800000001.s3-website-us-east-1.amazonaws.com"

Next Step: You have a solid, resilient backend. Would you like to secure the frontend by putting CloudFront (CDN) in front of your S3 bucket (which enables HTTPS and caching), or would you prefer to explore Log Monitoring to set up an alarm when items hit the DLQ?