------------ create and activate virtual environment----------------------

### 1. Prerequisites (One-time setup)

First, ensure the `venv` module is installed on your system.

```bash
sudo apt update
sudo apt install python3-venv

```

### 2. Create the Virtual Environment

Navigate to your project directory and run the following command. Replace `my_env` with whatever name you want to give your environment.

```bash
python3 -m venv my_env

```

### 3. Activate the Environment

To start using the environment, you must source the activate script.

```bash
source my_env/bin/activate

```

* **Visual Indicator:** You will know it is active because your terminal prompt will change to show the environment name, like this: `(my_env) user@hostname:~$`.

---

### Useful Tips

* **To Deactivate:** When you are done working, simply type:
```bash
deactivate

```


* **To Check:** To verify you are using the virtual environment's Python, run:
```bash
which python

```


It should point to the `bin` folder inside your virtual environment directory, not `/usr/bin/python`.

**Would you like a command to generate a `requirements.txt` file once you start installing packages?**

-------------- import error------------------

The error **"Import 'boto3' could not be resolved"** usually means either the package isn't installed in your current environment, or your code editor (like VS Code) is looking at the wrong Python installation.

Here is how to fix it:

### 1. The Terminal Fix (Install the Package)

Most of the time, `boto3` is simply missing from your virtual environment.

1. **Ensure your environment is active.** Look for the `(my_env)` prefix in your terminal. If you don't see it, run:
```bash
source my_env/bin/activate

```


2. **Install boto3:**
```bash
pip install boto3

```



### 2. The VS Code Fix (Select Interpreter)

If you have installed `boto3` but still see a yellow/red squiggly line with this error in VS Code, the editor is likely using the system Python instead of your virtual environment.

1. Open your project in VS Code.
2. Press **`Ctrl` + `Shift` + `P**` to open the Command Palette.
3. Type and select **"Python: Select Interpreter"**.
4. Look for the entry that says **`('my_env': venv)`** or points to `./my_env/bin/python`. Select that one.
5. Restart your terminal inside VS Code (`Ctrl` + ```) to ensure it picks up the change.

### 3. Verification

To verify `boto3` is installed and reachable, run this quick one-liner in your terminal:

```bash
python -c "import boto3; print(boto3.__version__)"

```

If it prints a version number (e.g., `1.34.x`), you are good to go.

**Would you like a sample `main.py` script to test your AWS connection with boto3?**


-------------- Understand CORS -------------------

This is great progress. The fact that items appear in DynamoDB means your **entire backend logic is working** (API -> Lambda -> SQS -> Lambda -> DB).

The reason you don't see the "Order placed successfully" alert is a **CORS (Cross-Origin Resource Sharing)** issue.

### 1. The "Why" & Diagnosis

Your web page is hosted on an S3 Bucket (e.g., `http://serverless-frontend...`), but it is trying to talk to an API Gateway (e.g., `https://xyz.execute-api...`). Browsers block this by default for security unless the API explicitly says, "It is safe for this website to read my response."

Currently, your `producer.py` sends back a `200 OK` status, but it doesn't send the `Access-Control-Allow-Origin` header. So, the browser sends the data, the backend processes it, but the browser **blocks the response** from reaching your JavaScript code.

### 2. The Solution (Python Update)

We need to tell the Producer Lambda to inject these security headers into the response.

#### **Step A: Update `producer.py**`

Modify your `producer.py` file to include the `headers` block in the return statement.

```python
import json
import boto3
import os

sqs = boto3.client('sqs')
QUEUE_URL = os.environ['SQS_QUEUE_URL']

def lambda_handler(event, context):
    try:
        # 1. Parse incoming body from API Gateway
        body = json.loads(event['body'])
        
        # 2. Send message to SQS
        sqs.send_message(
            QueueUrl=QUEUE_URL,
            MessageBody=json.dumps(body)
        )
        
        return {
            'statusCode': 200,
            # --- CORS HEADERS START ---
            'headers': {
                'Access-Control-Allow-Origin': '*', # Allows any domain to read the response
                'Access-Control-Allow-Headers': 'Content-Type',
                'Access-Control-Allow-Methods': 'OPTIONS,POST,GET'
            },
            # --- CORS HEADERS END ---
            'body': json.dumps('Order placed successfully!')
        }
    except Exception as e:
        return {
            'statusCode': 500,
            # Add headers here too in case of error!
            'headers': {
                'Access-Control-Allow-Origin': '*',
                'Access-Control-Allow-Headers': 'Content-Type',
                'Access-Control-Allow-Methods': 'OPTIONS,POST,GET'
            },
            'body': str(e)
        }

```

#### **Step B: Redeploy with Terraform**

Since you changed the Python code, Terraform needs to re-zip it and update the Lambda function.

1. Run the apply command again:
```bash
terraform apply -auto-approve

```


2. Wait for it to finish (it will detect the change in `producer.py` hash).

### 3. Verification & Troubleshooting

1. Refresh your S3 website page.
2. **Open Developer Tools (F12)** -> Go to the **Console** tab.
3. Click "Buy Now".
4. You should now see the alert.

**Still not working?**
If the Console says `CORS Preflight Did Not Succeed`, it means your browser is trying to send a "Preflight" (OPTIONS) check before the POST. This happens if you set specific headers (like `Content-Type: application/json`) in your HTML/JS.

If that happens, you have two choices:

1. **Simpler:** Ensure your HTML/JS `fetch` call does **not** manually set `Content-Type: application/json` (let it default to text/plain, which avoids the preflight check).
2. **Robust:** We must add an `OPTIONS` method to the API Gateway in Terraform. (Let me know if you need this code blockâ€”it is verbose but standard for production apps).

For now, the Python fix above solves 90% of basic connectivity issues!

-----------------------------

api_url = "https://1tey439377.execute-api.us-east-1.amazonaws.com/prod/order"
website_url = "serverless-frontend-20260113002820771100000001.s3-website-us-east-1.amazonaws.com"